{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs622_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "ResNet50V2"
      ],
      "metadata": {
        "id": "_Gj519T8HvrG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbaMErWzPC-T"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn import metrics\n",
        "from skimage import exposure"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORT AND PREPROCSSING "
      ],
      "metadata": {
        "id": "-gg1xf0tH20b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = np.load('/content/drive/MyDrive/school/CS/cs622/skincancer/test_dataset/x_test.npy')\n",
        "x_train = np.load('/content/drive/MyDrive/school/CS/cs622/skincancer/train_dataset/x_train.npy')\n",
        "y_train = np.load('/content/drive/MyDrive/school/CS/cs622/skincancer/train_dataset/y_train.npy')[:,0].reshape((2000,1))\n",
        "y_test = np.load('/content/drive/MyDrive/school/CS/cs622/skincancer/test_dataset/y_test.npy')[:,0].reshape((120,1))\n",
        "\n",
        "def histogram_equalize(img):\n",
        "    img = img.reshape((16384,))\n",
        "    img_cdf, bin_centers = exposure.cumulative_distribution(img)\n",
        "    return np.interp(img, bin_centers, img_cdf).reshape((128,128,1))\n",
        "for i in range(x_test.shape[0]):\n",
        "  x_train[i] = histogram_equalize(x_train[i])\n",
        "  x_test[i] = histogram_equalize(x_test[i])\n",
        "\n",
        "x_test = np.concatenate((x_test,)*3, axis=-1)\n",
        "x_train = np.concatenate((x_train,)*3, axis=-1)"
      ],
      "metadata": {
        "id": "4khCfzzTQv_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"number of training data: \",y_train.shape[0])\n",
        "print(\"number of benign in training data: \",np.count_nonzero(y_train))"
      ],
      "metadata": {
        "id": "RRDTZ53qGvf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kf = StratifiedKFold(n_splits=10,shuffle=True)\n",
        "print(\"number of folds: \",kf.get_n_splits(x_train))"
      ],
      "metadata": {
        "id": "8UzuqkkKIQ8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Acc=np.array([])\n",
        "# 0 malignant 1 benign\n",
        "for train_index, test_index in kf.split(x_train, y_train):\n",
        "  tf.keras.backend.clear_session()\n",
        "  model = tf.keras.applications.resnet_v2.ResNet50V2(include_top = False,input_shape = (128,128,3),classes=2,weights='imagenet')\n",
        "  for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "  x = tf.keras.layers.Flatten()(model.output)\n",
        "  x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
        "  x = tf.keras.layers.Dropout(0.5)(x)\n",
        "  x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
        "  x = tf.keras.layers.Dropout(0.5)(x)\n",
        "  predictions = tf.keras.layers.Dense(1, activation = 'sigmoid')(x)\n",
        "\n",
        "  head_model = tf.keras.Model(inputs = model.input, outputs = predictions)\n",
        "  head_model.compile(optimizer=tf.keras.optimizers.Adam(1e-5), loss=tf.keras.losses.binary_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "  \n",
        "  history = head_model.fit(x_train[train_index], y_train[train_index], batch_size=16, epochs=10, validation_data=(x_train[test_index],y_train[test_index]))\n",
        "  predic = head_model.predict(x_test)\n",
        "  predic = np.where(predic > 0.5, 1, 0)\n",
        "  print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y_test, predic))\n",
        "  Acc = np.append(Acc,[metrics.accuracy_score(y_test, predic)])\n",
        "  print('------------------------------------------------------------------------------------------------------------------------------------')\n",
        "print(\"AVERAGE TEST SCORE: \",np.average(Acc))"
      ],
      "metadata": {
        "id": "GPnyGl2yUXlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RANDOM FOREST & LOGISTIC REGRESSION"
      ],
      "metadata": {
        "id": "SgqFbzcdNYUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics \n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import RandomizedSearchCV,GridSearchCV"
      ],
      "metadata": {
        "id": "-PnVm92a4jZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = x_test[:,:,:,:1].reshape((120,16384))\n",
        "x_train = x_train[:,:,:,:1].reshape((2000,16384))\n",
        "\n",
        "X = np.concatenate((x_train,x_test),axis=0).reshape((2120,16384))\n",
        "\n",
        "y_train = np.load('/content/drive/MyDrive/school/CS/cs622/skincancer/train_dataset/y_train.npy')[:,0].reshape((2000,))\n",
        "y_test = np.load('/content/drive/MyDrive/school/CS/cs622/skincancer/test_dataset/y_test.npy')[:,0].reshape((120,))\n",
        "\n",
        "Y = np.concatenate((y_train,y_test),axis=0).reshape((2120,))\n"
      ],
      "metadata": {
        "id": "JShxP6PrtnZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of trees in random forest\n",
        "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 200, num = 10)]\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto', 'sqrt','log2']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
        "max_depth.append(None)\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [int(x) for x in np.linspace(1, 100, num = 11)]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True, False]\n",
        "\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap\n",
        "               }"
      ],
      "metadata": {
        "id": "PDH7CLwFYBIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cl = RandomForestClassifier()\n",
        "rf_random = RandomizedSearchCV(estimator = cl, \n",
        "                               param_distributions = random_grid, \n",
        "                               n_iter = 100, \n",
        "                               cv = 10, verbose=2, random_state=42)\n",
        "# Fit the random search model\n",
        "rf_random.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "KoCv3BwIYNc8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(rf_random.best_params_)"
      ],
      "metadata": {
        "id": "qB13SzK-gXqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(rf_random.best_score_)"
      ],
      "metadata": {
        "id": "BSYMBxOsOtil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of trees in random forest\n",
        "n_e = [int(x) for x in np.linspace(start = 180, stop = 190, num = 6)]\n",
        "# Number of features to consider at every split\n",
        "max_f = ['sqrt']\n",
        "# Maximum number of levels in tree\n",
        "max_d = [110]\n",
        "# Minimum number of samples required to split a node\n",
        "min_ss = [int(x) for x in np.linspace(2, 5, num = 5)]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_sl = [1]\n",
        "# Method of selecting samples for training each tree\n",
        "b = ['False']\n",
        "\n",
        "grid = {'n_estimators': n_e,\n",
        "               'max_features': max_f,\n",
        "               'max_depth': max_d,\n",
        "               'min_samples_split': min_ss,\n",
        "               'min_samples_leaf': min_sl,\n",
        "               'bootstrap': b,\n",
        "               }\n",
        "cl = RandomForestClassifier()\n",
        "rf_grid = GridSearchCV(estimator = cl, param_grid = grid,  cv = 10, verbose=3)\n",
        "# Fit the random search model\n",
        "rf_grid.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "Bi3PvVakTlsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_grid.best_params_"
      ],
      "metadata": {
        "id": "iDGMUrdCYWms"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_grid.best_score_"
      ],
      "metadata": {
        "id": "3R6nUkqMhuu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cl = RandomForestClassifier()\n",
        "y_pred = cl.predict(x_test)\n",
        "print(\"ACCURACY OF THE MODEL: \", metrics.accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "D7zmuVBzqhVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "yifJhX90qivN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "C = np.logspace(-4, 4, 20)\n",
        "solver = ['lbfgs', 'saga']\n",
        "\n",
        "grid = {'C': C,\n",
        "        'solver': solver,\n",
        "        }\n",
        "cl = LogisticRegression()\n",
        "LR_grid = GridSearchCV(estimator = cl, param_grid = grid,  cv = 10, verbose=2)\n",
        "LR_grid.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "6F7MPIvMNKPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(LR_grid.best_params_)"
      ],
      "metadata": {
        "id": "nduKMW4cj-Pm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(LR_grid.best_score_)"
      ],
      "metadata": {
        "id": "aDdikSVxkFko"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}